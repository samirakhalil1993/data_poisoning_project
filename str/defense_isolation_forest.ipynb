{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd9b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# DEFENSE MED ISOLATION FOREST\n",
    "# Detekterar och tar bort misst√§nkta poisoned exempel\n",
    "# ------------------------------------------------------\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, DistilBertModel\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import torch\n",
    "import csv, os, random\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Save results funktion\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def save_results(attack_type, attack_rate, accuracy, f1, train_size, confusion_matrix, \n",
    "                 defense_used=None, removed_count=None, filename=\"results/logs/defense_flip.csv\"):\n",
    "    \n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    \n",
    "    file_exists = os.path.isfile(filename)\n",
    "\n",
    "    with open(filename, mode=\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"attack_type\", \"attack_rate\", \"accuracy\", \"f1\", \n",
    "                           \"train_size\", \"confusion_matrix\", \"defense_used\", \"removed_count\"])\n",
    "\n",
    "        writer.writerow([\n",
    "            attack_type,\n",
    "            attack_rate,\n",
    "            accuracy,\n",
    "            f1,\n",
    "            train_size,\n",
    "            confusion_matrix.tolist(),\n",
    "            defense_used,\n",
    "            removed_count\n",
    "        ])\n",
    "\n",
    "    print(f\"‚úî Resultat sparat i {filename}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. Flip-label funktion (samma som tidigare)\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def flip_labels(dataset, percentage=0.1):\n",
    "    \"\"\"Flips percentage of labels (1 ‚Üí 0, 0 ‚Üí 1).\"\"\"\n",
    "    n = len(dataset)\n",
    "    k = int(n * percentage)\n",
    "\n",
    "    poisoned = dataset.select(range(n))\n",
    "    flip_idx = random.sample(range(n), k)\n",
    "\n",
    "    def flip(example, idx):\n",
    "        lbl = example[\"label\"]\n",
    "        if idx in flip_idx:\n",
    "            example[\"label\"] = 1 - lbl\n",
    "        return example\n",
    "\n",
    "    poisoned = poisoned.map(flip, with_indices=True)\n",
    "    return poisoned, flip_idx\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. Extrahera embeddings fr√•n DistilBERT\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def extract_embeddings(dataset, tokenizer, model_name=\"distilbert-base-uncased\", device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Extraherar CLS-token embeddings fr√•n DistilBERT f√∂r varje exempel.\n",
    "    \"\"\"\n",
    "    model = DistilBertModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    print(f\"Extraherar embeddings f√∂r {len(dataset)} exempel...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, example in enumerate(dataset):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"  {i}/{len(dataset)}\", end=\"\\r\")\n",
    "            \n",
    "            inputs = tokenizer(\n",
    "                example[\"text\"], \n",
    "                return_tensors=\"pt\", \n",
    "                truncation=True, \n",
    "                padding=\"max_length\", \n",
    "                max_length=256\n",
    "            ).to(device)\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            # Anv√§nd CLS token (f√∂rsta token) som representation\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(cls_embedding[0])\n",
    "    \n",
    "    print(f\"\\n‚úî Embeddings extraherade: {len(embeddings)}\")\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4. IsolationForest f√∂r att detektera outliers\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def detect_outliers(embeddings, contamination=0.1):\n",
    "    \"\"\"\n",
    "    Anv√§nder IsolationForest f√∂r att identifiera outliers.\n",
    "    contamination: f√∂rv√§ntad andel outliers (motsvarar poison rate)\n",
    "    \"\"\"\n",
    "    print(f\"\\nK√∂r IsolationForest med contamination={contamination}\")\n",
    "    \n",
    "    iso_forest = IsolationForest(\n",
    "        contamination=contamination,\n",
    "        random_state=42,\n",
    "        n_estimators=100\n",
    "    )\n",
    "    \n",
    "    predictions = iso_forest.fit_predict(embeddings)\n",
    "    # -1 = outlier, 1 = inlier\n",
    "    outlier_indices = np.where(predictions == -1)[0]\n",
    "    \n",
    "    print(f\"‚úî Detekterade {len(outlier_indices)} outliers\")\n",
    "    return outlier_indices\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 5. Ta bort outliers fr√•n dataset\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def remove_outliers(dataset, outlier_indices):\n",
    "    \"\"\"Tar bort exempel p√• specificerade index.\"\"\"\n",
    "    all_indices = set(range(len(dataset)))\n",
    "    keep_indices = sorted(list(all_indices - set(outlier_indices)))\n",
    "    \n",
    "    cleaned_dataset = dataset.select(keep_indices)\n",
    "    print(f\"‚úî Dataset rensat: {len(dataset)} ‚Üí {len(cleaned_dataset)} exempel\")\n",
    "    \n",
    "    return cleaned_dataset\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 6. HUVUDEXPERIMENT: Label Flipping Defense\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "ATTACK_RATE = 0.10  # √Ñndra detta f√∂r olika experiment\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Attack rate: {ATTACK_RATE * 100}%\\n\")\n",
    "\n",
    "# Ladda dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "train = dataset[\"train\"].shuffle(seed=42).select(range(500))\n",
    "val   = dataset[\"test\"].shuffle(seed=42).select(range(250))\n",
    "test  = dataset[\"test\"].shuffle(seed=42).select(range(250))\n",
    "\n",
    "print(\"Dataset loaded:\", len(train), len(val), len(test))\n",
    "\n",
    "# Skapa poisoned data\n",
    "poisoned_train, flipped_idx = flip_labels(train, percentage=ATTACK_RATE)\n",
    "print(f\"Antal flippade exempel: {len(flipped_idx)}\")\n",
    "\n",
    "# Extrahera embeddings\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "embeddings = extract_embeddings(poisoned_train, tokenizer, device=DEVICE)\n",
    "\n",
    "# Detektera outliers\n",
    "outlier_indices = detect_outliers(embeddings, contamination=ATTACK_RATE)\n",
    "\n",
    "# Analysera hur m√•nga poisoned exempel som f√•ngades\n",
    "detected_poisoned = len(set(outlier_indices) & set(flipped_idx))\n",
    "false_positives = len(set(outlier_indices) - set(flipped_idx))\n",
    "missed_poisoned = len(set(flipped_idx) - set(outlier_indices))\n",
    "\n",
    "print(f\"\\nüìä Detection Analysis:\")\n",
    "print(f\"  Total poisoned examples: {len(flipped_idx)}\")\n",
    "print(f\"  Detected outliers: {len(outlier_indices)}\")\n",
    "print(f\"  True positives (poisoned detected): {detected_poisoned}\")\n",
    "print(f\"  False positives (clean flagged): {false_positives}\")\n",
    "print(f\"  False negatives (poisoned missed): {missed_poisoned}\")\n",
    "print(f\"  Detection rate: {detected_poisoned/len(flipped_idx)*100:.1f}%\")\n",
    "\n",
    "# Rensa dataset\n",
    "cleaned_train = remove_outliers(poisoned_train, outlier_indices)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 7. Tokenisering\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "train_tok = cleaned_train.map(tokenize, batched=True)\n",
    "val_tok   = val.map(tokenize, batched=True)\n",
    "test_tok  = test.map(tokenize, batched=True)\n",
    "\n",
    "train_tok = train_tok.rename_column(\"label\", \"labels\")\n",
    "val_tok   = val_tok.rename_column(\"label\", \"labels\")\n",
    "test_tok  = test_tok.rename_column(\"label\", \"labels\")\n",
    "\n",
    "train_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 8. Tr√§na modell p√• rensad data\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"defense_output_rate_{int(ATTACK_RATE * 100)}\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Tr√§nar modell p√• rensad data...\")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 9. Utv√§rdera modellen\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nüìä Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(test_tok)\n",
    "print(test_results)\n",
    "\n",
    "test_accuracy = test_results[\"eval_accuracy\"]\n",
    "test_f1 = test_results[\"eval_f1\"]\n",
    "\n",
    "# Confusion matrix\n",
    "pred_out = trainer.predict(test_tok)\n",
    "logits = pred_out.predictions\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "y_true = pred_out.label_ids\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nConfusion Matrix (defended):\")\n",
    "print(cm)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 10. Spara resultat\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "save_results(\n",
    "    attack_type=\"label_flip_defended\",\n",
    "    attack_rate=ATTACK_RATE,\n",
    "    accuracy=test_accuracy,\n",
    "    f1=test_f1,\n",
    "    train_size=len(cleaned_train),\n",
    "    confusion_matrix=cm,\n",
    "    defense_used=\"IsolationForest\",\n",
    "    removed_count=len(outlier_indices)\n",
    ")\n",
    "\n",
    "print(\"\\n‚úî DEFENSE EXPERIMENT KLAR!\")\n",
    "print(f\"Final accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Removed {len(outlier_indices)} examples ({len(outlier_indices)/len(poisoned_train)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
